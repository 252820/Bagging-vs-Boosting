{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用sklearn的函数来获取MNIST数据集\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "# 全局取消证书验证\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据集所用时间: 46.283408641815186\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time_begin=time.time()\n",
    "mnist=fetch_openml('mnist_784')\n",
    "time_end=time.time()\n",
    "time_data=time_end-time_begin\n",
    "print('加载数据集所用时间:',time_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y=mnist['data'],mnist['target']\n",
    "X.shape #数据X共有7万张图片，每张图片有784个特征。因为图片是28×28像素，每个特征代表了一个像素点的强度，从0（白色）到255（黑色），"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基分类器1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8696666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "start_time_base1=time.time()\n",
    "classifier1=DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=18,min_samples_split=5,random_state=42)#第一次测试最优\n",
    "classifier1.fit(X_train,y_train)\n",
    "score1=classifier1.score(X_test,y_test)\n",
    "print(score1)\n",
    "end_time_base1=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基分类器所用时间： 27.306578397750854\n"
     ]
    }
   ],
   "source": [
    "base_time1=end_time_base1-start_time_base1\n",
    "print('基分类器所用时间：',base_time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_mnist/base1_learner_mnist.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "#保存Model\n",
    "joblib.dump(classifier1,'model_mnist/base1_learner_mnist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6030960083007812\n"
     ]
    }
   ],
   "source": [
    "print(os.path.getsize('model_mnist/base1_learner_mnist.pkl')/1024/1024) #MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir_size(target_dir):\n",
    "    pkl_size=[] #MB\n",
    "    dir_list=os.listdir(target_dir)\n",
    "    print(dir_list)\n",
    "    #计算每个文件的大小\n",
    "    for file in dir_list:\n",
    "        file = os.path.join(target_dir, file)\n",
    "        #如果是文件，直接通过getsize计算大小并加到size中\n",
    "        if os.path.isfile(file):\n",
    "            pkl_size.append(os.path.getsize(file)/1024/1024) #MB\n",
    "    return pkl_size\n",
    "#没按理想顺序排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def bagging_clf(base_learner,target_dir,n):\n",
    "    #性能指标\n",
    "    time_bagging=[] #s\n",
    "    top1_bagging=[]\n",
    "    \n",
    "#     n= [20,40,60,80,100,120,140,170,300,400,500]\n",
    "\n",
    "    \n",
    "    for i in tqdm(n):\n",
    "    \n",
    "        start_time_bagging=time.time()\n",
    "\n",
    "        # 创建Bagging集成学习器\n",
    "        bagging_clf = BaggingClassifier(base_estimator=base_learner, n_estimators=i, random_state=42,n_jobs=-1,bootstrap=True)\n",
    "        bagging_clf.fit(X_train, y_train)\n",
    "        y_pred_bagging = bagging_clf.predict(X_test)\n",
    "\n",
    "        # 评估性能\n",
    "    #     print(\"Bagging Accuracy:\", accuracy_score(y_test, y_pred_bagging))\n",
    "        top1_bagging.append(accuracy_score(y_test, y_pred_bagging))\n",
    "\n",
    "        end_time_bagging=time.time()\n",
    "        bagging_time=end_time_bagging-start_time_bagging\n",
    "    #     print('Bagging所用时间：',bagging_time)\n",
    "        time_bagging.append(bagging_time)\n",
    "\n",
    "        joblib.dump(bagging_clf,f'{target_dir}/bagging_mnist_{i}.pkl')\n",
    "    \n",
    "    return time_bagging,top1_bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 11/11 [1:08:03<00:00, 371.27s/it]\n"
     ]
    }
   ],
   "source": [
    "time_bagging1,top1_bagging1=bagging_clf(classifier1,'model_mnist/model1_bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bagging_mnist_100.pkl', 'bagging_mnist_120.pkl', 'bagging_mnist_140.pkl', 'bagging_mnist_170.pkl', 'bagging_mnist_20.pkl', 'bagging_mnist_300.pkl', 'bagging_mnist_40.pkl', 'bagging_mnist_400.pkl', 'bagging_mnist_500.pkl', 'bagging_mnist_60.pkl', 'bagging_mnist_80.pkl']\n"
     ]
    }
   ],
   "source": [
    "pkl_size_bagging1=get_dir_size('model_mnist/model1_bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    基分类器个数  performance           时间  pkl_size_bagging1\n",
      "0       20     0.950667    45.250962          45.023484\n",
      "1       40     0.951381    78.520336          53.945835\n",
      "2       60     0.952714   110.638683          62.865065\n",
      "3       80     0.953429   181.730240          76.296826\n",
      "4      100     0.951667   219.069227           9.492064\n",
      "5      120     0.952619   240.434104         134.295970\n",
      "6      140     0.953143   304.146207          18.390792\n",
      "7      170     0.953095   369.168261         178.836874\n",
      "8      300     0.954476   609.535818         223.488550\n",
      "9      400     0.954762   879.549972          27.278916\n",
      "10     500     0.954524  1040.362046          36.135383\n"
     ]
    }
   ],
   "source": [
    "#保存结果\n",
    "n= [20,40,60,80,100,120,140,170,300,400,500]\n",
    "import pandas as pd\n",
    "c1={\"基分类器个数\" : n,\n",
    "   \"performance\" : top1_bagging1,\n",
    "  \"时间\":time_bagging1,\n",
    "  \"pkl_size_bagging1\":pkl_size_bagging1}#将列表a，b转换成字典\n",
    "bagging_result1=pd.DataFrame(c1)#将字典转换成为数据框\n",
    "print(bagging_result1)\n",
    "bagging_result1.to_csv('model_mnist/bagging_MNIST_result1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def boosting_clf(base_learner,target_dir,n):\n",
    "\n",
    "    #性能指标\n",
    "    time_boosting=[] #s\n",
    "    top1_boosting=[]\n",
    "\n",
    "#     n= [20,40,60,80,100,120,140,170,300,400,500]\n",
    "#     n= [20,40,60,80,100,120,140,170,200,300]\n",
    "\n",
    "    for i in tqdm(n):\n",
    "\n",
    "        start_time_boosting=time.time()\n",
    "\n",
    "        # 创建Bagging集成学习器\n",
    "        boosting_clf = AdaBoostClassifier(base_estimator=base_learner, n_estimators=i, random_state=42)\n",
    "        boosting_clf.fit(X_train, y_train)\n",
    "        y_pred_boosting = boosting_clf.predict(X_test)\n",
    "\n",
    "        # 评估性能\n",
    "        top1_boosting.append(accuracy_score(y_test, y_pred_boosting))\n",
    "\n",
    "        end_time_boosting=time.time()\n",
    "        boosting_time=end_time_boosting-start_time_boosting\n",
    "        time_boosting.append(boosting_time)\n",
    "        \n",
    "        joblib.dump(boosting_clf,f'{target_dir}/boosting_mnist_{i}.pkl')    \n",
    "    \n",
    "    return time_boosting,top1_boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/11 [01:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-58ee43490286>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m140\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m170\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtime_boosting1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop1_boosting1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mboosting_clf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'model_mnist/model1_boosting'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-086c349fdd8a>\u001b[0m in \u001b[0;36mboosting_clf\u001b[1;34m(base_learner, target_dir, n)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# 创建Bagging集成学习器\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mboosting_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_learner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mboosting_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0my_pred_boosting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboosting_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0miboost\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;31m# Boosting step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[0;32m    131\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \"\"\"\n\u001b[0;32m    502\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SAMME.R'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \"\"\"\n\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    891\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time_boosting1,top1_boosting1=boosting_clf(classifier1,'model_mnist/model1_boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看错了，导致点错了，还好保存了csv，下次注释写清楚点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_size_boosting1=get_dir_size('model_mnist/model1_boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存结果\n",
    "import pandas as pd\n",
    "cb1={\"基分类器个数\" : n,\n",
    "   \"performance\" : top1_boosting1,\n",
    "  \"时间\":time_boosting1,\n",
    "  \"pkl_size_boosting1\":pkl_size_boosting1}#将列表a，b转换成字典\n",
    "boost_result1=pd.DataFrame(cb1)#将字典转换成为数据框\n",
    "print(boost_result1)\n",
    "boost_result1.to_csv('model_mnist/boosting_MNIST_result1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基分类器2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8536666666666667\n"
     ]
    }
   ],
   "source": [
    "start_time_base2=time.time()\n",
    "classifier2=DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=10,min_samples_split=5,random_state=42)#第一次测试最优\n",
    "classifier2.fit(X_train,y_train)\n",
    "score2=classifier2.score(X_test,y_test)\n",
    "print(score2)\n",
    "end_time_base2=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基分类器所用时间： 18.06419563293457\n"
     ]
    }
   ],
   "source": [
    "base_time2=end_time_base2-start_time_base2\n",
    "print('基分类器所用时间：',base_time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_mnist/base2_learner_mnist.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "#保存Model\n",
    "joblib.dump(classifier2,'model_mnist/base2_learner_mnist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21736907958984375\n"
     ]
    }
   ],
   "source": [
    "print(os.path.getsize('model_mnist/base2_learner_mnist.pkl')/1024/1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 11/11 [41:03<00:00, 223.95s/it]\n"
     ]
    }
   ],
   "source": [
    "time_bagging2,top1_bagging2=bagging_clf(classifier2,'model_mnist/model2_bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bagging_mnist_100.pkl', 'bagging_mnist_120.pkl', 'bagging_mnist_140.pkl', 'bagging_mnist_170.pkl', 'bagging_mnist_20.pkl', 'bagging_mnist_300.pkl', 'bagging_mnist_40.pkl', 'bagging_mnist_400.pkl', 'bagging_mnist_500.pkl', 'bagging_mnist_60.pkl', 'bagging_mnist_80.pkl']\n"
     ]
    }
   ],
   "source": [
    "pkl_size_bagging2=get_dir_size('model_mnist/model2_bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    基分类器个数  performance          时间  pkl_size_bagging\n",
      "0       20     0.931571   29.990106         19.370698\n",
      "1       40     0.932571   54.064914         23.189106\n",
      "2       60     0.932476   80.307544         26.994276\n",
      "3       80     0.932619  101.904251         32.805402\n",
      "4      100     0.931762  132.199790          4.008879\n",
      "5      120     0.931571  153.232098         57.668086\n",
      "6      140     0.931714  179.325649          7.878890\n",
      "7      170     0.932238  219.361088         76.696020\n",
      "8      300     0.932476  378.843054         95.927073\n",
      "9      400     0.933095  504.451967         11.713136\n",
      "10     500     0.933048  626.647793         15.529990\n"
     ]
    }
   ],
   "source": [
    "#保存结果\n",
    "import pandas as pd\n",
    "c2={\"基分类器个数\" : n,\n",
    "   \"performance\" : top1_bagging2,\n",
    "  \"时间\":time_bagging2,\n",
    "  \"pkl_size_bagging\":pkl_size_bagging2}#将列表a，b转换成字典\n",
    "bagging_result2=pd.DataFrame(c2)#将字典转换成为数据框\n",
    "print(bagging_result2)\n",
    "bagging_result2.to_csv('model_mnist/bagging_MNIST_result2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 11/11 [9:35:21<00:00, 3138.36s/it]\n"
     ]
    }
   ],
   "source": [
    "n= [20,40,60,80,100,120,140,170,300,400,500]\n",
    "time_boosting2,top1_boosting2=boosting_clf(classifier2,'model_mnist/model2_boosting',n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(time_boosting,top1_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boosting_mnist_100.pkl', 'boosting_mnist_120.pkl', 'boosting_mnist_140.pkl', 'boosting_mnist_170.pkl', 'boosting_mnist_20.pkl', 'boosting_mnist_300.pkl', 'boosting_mnist_40.pkl', 'boosting_mnist_400.pkl', 'boosting_mnist_500.pkl', 'boosting_mnist_60.pkl', 'boosting_mnist_80.pkl']\n"
     ]
    }
   ],
   "source": [
    "pkl_size_boosting2=get_dir_size('model_mnist/model2_boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    基分类器个数  performance           时间  pkl_size_boosting1\n",
      "0       20     0.911619   416.166608           12.620796\n",
      "1       40     0.932810   792.731243           14.685902\n",
      "2       60     0.941952  1170.273323           17.057098\n",
      "3       80     0.945667  1564.946035           20.457346\n",
      "4      100     0.950286  1955.616270            3.095284\n",
      "5      120     0.953238  2350.902061           36.451831\n",
      "6      140     0.954095  2733.736177            5.558567\n",
      "7      170     0.956905  3277.244351           48.188750\n",
      "8      300     0.960048  5514.028136           59.978068\n",
      "9      400     0.962381  6802.416414            8.043121\n",
      "10     500     0.963619  7941.578051           10.311337\n"
     ]
    }
   ],
   "source": [
    "#保存结果\n",
    "import pandas as pd\n",
    "cb2={\"基分类器个数\" : n,\n",
    "   \"performance\" : top1_boosting2,\n",
    "  \"时间\":time_boosting2,\n",
    "  \"pkl_size_boosting1\":pkl_size_boosting2}#将列表a，b转换成字典\n",
    "boost_result2=pd.DataFrame(cb2)#将字典转换成为数据框\n",
    "print(boost_result2)\n",
    "boost_result2.to_csv('model_mnist/boosting_MNIST_result2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跑完中断服务再运行函数 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重跑bagging/boosting函数后再运行下列实验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基分类器3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8048095238095239\n"
     ]
    }
   ],
   "source": [
    "start_time_base3=time.time()\n",
    "classifier3=DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=8,min_samples_split=5,random_state=42)#第一次测试最优\n",
    "classifier3.fit(X_train,y_train)\n",
    "score3=classifier3.score(X_test,y_test)\n",
    "print(score3)\n",
    "end_time_base3=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基分类器所用时间： 16.20579433441162\n"
     ]
    }
   ],
   "source": [
    "base_time3=end_time_base3-start_time_base3\n",
    "print('基分类器所用时间：',base_time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_mnist/base3_learner_mnist.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "#保存Model\n",
    "joblib.dump(classifier3,'model_mnist/base3_learner_mnist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06743621826171875\n"
     ]
    }
   ],
   "source": [
    "print(os.path.getsize('model_mnist/base3_learner_mnist.pkl')/1024/1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [17:32<00:00, 105.25s/it]\n"
     ]
    }
   ],
   "source": [
    "n= [20,40,60,80,100,120,140,170,200,300]\n",
    "time_bagging3,top1_bagging3=bagging_clf(classifier3,'model_mnist/model3_bagging',n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bagging_mnist_100.pkl', 'bagging_mnist_120.pkl', 'bagging_mnist_140.pkl', 'bagging_mnist_170.pkl', 'bagging_mnist_20.pkl', 'bagging_mnist_200.pkl', 'bagging_mnist_300.pkl', 'bagging_mnist_40.pkl', 'bagging_mnist_60.pkl', 'bagging_mnist_80.pkl']\n"
     ]
    }
   ],
   "source": [
    "pkl_size_bagging3=get_dir_size('model_mnist/model3_bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   基分类器个数  performance          时间  pkl_size_bagging\n",
      "0      20     0.896190   22.717244          6.870759\n",
      "1      40     0.893905   39.213464          8.224613\n",
      "2      60     0.892524   50.972113          9.571714\n",
      "3      80     0.892286   69.572621         11.620252\n",
      "4     100     0.890476   86.770426          1.415663\n",
      "5     120     0.890619  101.528722         13.646489\n",
      "6     140     0.891333  117.682910         20.432857\n",
      "7     170     0.890762  143.290583          2.791030\n",
      "8     200     0.891048  169.517843          4.146714\n",
      "9     300     0.892238  249.688899          5.504981\n"
     ]
    }
   ],
   "source": [
    "#保存结果\n",
    "import pandas as pd\n",
    "n= [20,40,60,80,100,120,140,170,200,300]\n",
    "c3={\"基分类器个数\" : n,\n",
    "   \"performance\" : top1_bagging3,\n",
    "  \"时间\":time_bagging3,\n",
    "  \"pkl_size_bagging\":pkl_size_bagging3}#将列表a，b转换成字典\n",
    "bagging_result3=pd.DataFrame(c3)#将字典转换成为数据框\n",
    "print(bagging_result3)\n",
    "bagging_result3.to_csv('model_mnist/bagging_MNIST_result3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 10/10 [5:40:27<00:00, 2042.76s/it]\n"
     ]
    }
   ],
   "source": [
    "n= [20,40,60,80,100,120,140,170,200,300]\n",
    "time_boosting3,top1_boosting3=boosting_clf(classifier3,'model_mnist/model3_boosting',n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boosting_mnist_100.pkl', 'boosting_mnist_120.pkl', 'boosting_mnist_140.pkl', 'boosting_mnist_170.pkl', 'boosting_mnist_20.pkl', 'boosting_mnist_200.pkl', 'boosting_mnist_300.pkl', 'boosting_mnist_40.pkl', 'boosting_mnist_60.pkl', 'boosting_mnist_80.pkl']\n"
     ]
    }
   ],
   "source": [
    "pkl_size_boosting3=get_dir_size('model_mnist/model3_boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   基分类器个数  performance           时间  pkl_size_boosting1\n",
      "0      20     0.878095   340.244428            4.807401\n",
      "1      40     0.902619   681.822877            5.644752\n",
      "2      60     0.917048  1022.027747            6.473804\n",
      "3      80     0.925714  1359.982244            7.853319\n",
      "4     100     0.934143  1698.923945            1.170280\n",
      "5     120     0.935524  2038.498396            9.206897\n",
      "6     140     0.940048  2370.618853           13.435717\n",
      "7     170     0.944000  2850.202939            2.081050\n",
      "8     200     0.945810  3327.834531            3.003239\n",
      "9     300     0.950810  4736.178408            3.823991\n"
     ]
    }
   ],
   "source": [
    "#保存结果\n",
    "import pandas as pd\n",
    "cb3={\"基分类器个数\" : n,\n",
    "   \"performance\" : top1_boosting3,\n",
    "  \"时间\":time_boosting3,\n",
    "  \"pkl_size_boosting1\":pkl_size_boosting3}#将列表a，b转换成字典\n",
    "boost_result3=pd.DataFrame(cb3)#将字典转换成为数据框8\n",
    "print(boost_result3)\n",
    "boost_result3.to_csv('model_mnist/boosting_MNIST_result3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
