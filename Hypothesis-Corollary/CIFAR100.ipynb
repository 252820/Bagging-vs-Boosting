{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pickle\n",
    "# 加载数据集\n",
    "def load_cifar100_batch(filename):\n",
    "\n",
    "    with open(filename,'rb') as f:\n",
    "        datadict=pickle.load(f,encoding='latin1')\n",
    "        X=datadict['data']\n",
    "        Y=datadict['fine_labels']\n",
    "        Y=np.array(Y)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar100(root):\n",
    "    Xtr,Ytr=load_cifar100_batch(os.path.join(root,'train'))\n",
    "    Xte,Yte=load_cifar100_batch(os.path.join(root,'test'))\n",
    "    return Xtr,Ytr,Xte,Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr,Ytr,Xte,Yte=load_cifar100(\"./cifar100/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072) (50000,) (10000, 3072) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(Xtr.shape, Ytr.shape,Xte.shape,Yte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((Xtr,Xte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= np.concatenate((Ytr, Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 3072) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 3072)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 寻找最优决策树深度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08594444444444445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier=DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=10,min_samples_split=5,random_state=42)#第一次测试最优\n",
    "classifier.fit(X_train,y_train)\n",
    "score=classifier.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier=DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=50,min_samples_split=5,random_state=42)#第一次测试最优\n",
    "classifier.fit(X_train,y_train)\n",
    "score=classifier.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07922222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier=DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=30,min_samples_split=5,random_state=42)#第一次测试最优\n",
    "classifier.fit(X_train,y_train)\n",
    "score=classifier.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07927777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier=DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=80,min_samples_split=5,random_state=42)#第一次测试最优\n",
    "classifier.fit(X_train,y_train)\n",
    "score=classifier.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08016666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier=DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=100,min_samples_split=5,random_state=42)#第一次测试最优\n",
    "classifier.fit(X_train,y_train)\n",
    "score=classifier.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08172222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier=DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=8,min_samples_split=5,random_state=42)#第一次测试最优\n",
    "classifier.fit(X_train,y_train)\n",
    "score=classifier.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier=DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=5,min_samples_split=5,random_state=42)#第一次测试最优\n",
    "classifier.fit(X_train,y_train)\n",
    "score=classifier.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08427777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier=DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=15,min_samples_split=5,random_state=42)#第一次测试最优\n",
    "classifier.fit(X_train,y_train)\n",
    "score=classifier.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基分类器1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "start_time_base1=time.time()\n",
    "classifier1=DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=18,min_samples_split=5,random_state=42)#第一次测试最优\n",
    "classifier1.fit(X_train,y_train)\n",
    "score1=classifier1.score(X_test,y_test)\n",
    "print(score1)\n",
    "end_time_base1=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基分类器所用时间： 421.55856370925903\n"
     ]
    }
   ],
   "source": [
    "base_time1=end_time_base1-start_time_base1\n",
    "print('基分类器所用时间：',base_time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_cifar100/base1_learner_cifar100.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "#保存Model\n",
    "joblib.dump(classifier1,'model_cifar100/base1_learner_cifar100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.120092391967773\n"
     ]
    }
   ],
   "source": [
    "print(os.path.getsize('model_cifar100/base1_learner_cifar100.pkl')/1024/1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir_size(target_dir):\n",
    "    pkl_size=[] #MB\n",
    "    dir_list=os.listdir(target_dir)\n",
    "    print(dir_list)\n",
    "    #计算每个文件的大小\n",
    "    for file in dir_list:\n",
    "        file = os.path.join(target_dir, file)\n",
    "        #如果是文件，直接通过getsize计算大小并加到size中\n",
    "        if os.path.isfile(file):\n",
    "            pkl_size.append(os.path.getsize(file)/1024/1024) #MB\n",
    "    return pkl_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重跑这个函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def bagging_clf(base_learner,target_dir):\n",
    "    #性能指标\n",
    "    time_bagging=[] #s\n",
    "    top1_bagging=[]\n",
    "    \n",
    "#     n= [20,40,60,80,100,120,140,170,300,400,500]\n",
    "    n= [20,40,60,80,100,120,140,170,200,300]\n",
    "    \n",
    "    for i in tqdm(n):\n",
    "    \n",
    "        start_time_bagging=time.time()\n",
    "\n",
    "        # 创建Bagging集成学习器\n",
    "        bagging_clf = BaggingClassifier(base_estimator=base_learner, n_estimators=i, random_state=42,n_jobs=-1,bootstrap=True)\n",
    "        bagging_clf.fit(X_train, y_train)\n",
    "        y_pred_bagging = bagging_clf.predict(X_test)\n",
    "\n",
    "        # 评估性能\n",
    "    #     print(\"Bagging Accuracy:\", accuracy_score(y_test, y_pred_bagging))\n",
    "        top1_bagging.append(accuracy_score(y_test, y_pred_bagging))\n",
    "\n",
    "        end_time_bagging=time.time()\n",
    "        bagging_time=end_time_bagging-start_time_bagging\n",
    "    #     print('Bagging所用时间：',bagging_time)\n",
    "        time_bagging.append(bagging_time)\n",
    "\n",
    "        joblib.dump(bagging_clf,f'{target_dir}/bagging_cifar100_{i}.pkl')\n",
    "    \n",
    "    return time_bagging,top1_bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 11/11 [16:26:16<00:00, 5379.64s/it]\n"
     ]
    }
   ],
   "source": [
    "time_bagging1,top1_bagging1=bagging_clf(classifier1,'model_cifar100/model1_bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bagging_cifar100_100.pkl', 'bagging_cifar100_120.pkl', 'bagging_cifar100_140.pkl', 'bagging_cifar100_170.pkl', 'bagging_cifar100_20.pkl', 'bagging_cifar100_300.pkl', 'bagging_cifar100_40.pkl', 'bagging_cifar100_400.pkl', 'bagging_cifar100_500.pkl', 'bagging_cifar100_60.pkl', 'bagging_cifar100_80.pkl']\n"
     ]
    }
   ],
   "source": [
    "pkl_size_bagging1=get_dir_size('model_cifar100/model1_bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    基分类器个数  performance            时间  pkl_size_bagging1\n",
      "0       20     0.157056    627.943440         484.405025\n",
      "1       40     0.175944   1236.205108         579.197813\n",
      "2       60     0.184333   1590.830074         674.767754\n",
      "3       80     0.191778   2083.329652         816.479362\n",
      "4      100     0.194389   2612.214642         102.549736\n",
      "5      120     0.197778   3032.314652        1433.157369\n",
      "6      140     0.201389   3728.886504         197.941705\n",
      "7      170     0.202667   4777.291127        1908.936829\n",
      "8      300     0.207556   8821.450423        2383.049320\n",
      "9      400     0.207333  11460.187042         292.945125\n",
      "10     500     0.208333  19154.862211         389.308564\n"
     ]
    }
   ],
   "source": [
    "#保存结果\n",
    "import pandas as pd\n",
    "n= [20,40,60,80,100,120,140,170,300,400,500]\n",
    "c1={\"基分类器个数\" : n,\n",
    "   \"performance\" : top1_bagging1,\n",
    "  \"时间\":time_bagging1,\n",
    "  \"pkl_size_bagging1\":pkl_size_bagging1}#将列表a，b转换成字典\n",
    "bagging_result1=pd.DataFrame(c1)#将字典转换成为数据框\n",
    "print(bagging_result1)\n",
    "bagging_result1.to_csv('model_cifar100/bagging_cifar100_result1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def boosting_clf(base_learner,target_dir):\n",
    "\n",
    "    #性能指标\n",
    "    time_boosting=[] #s\n",
    "    top1_boosting=[]\n",
    "\n",
    "    n= [20,40,60,80,100,120,140,170,200,300]\n",
    "\n",
    "    for i in tqdm(n):\n",
    "\n",
    "        start_time_boosting=time.time()\n",
    "\n",
    "        # 创建Bagging集成学习器\n",
    "        boosting_clf = AdaBoostClassifier(base_estimator=base_learner, n_estimators=i, random_state=42)\n",
    "        boosting_clf.fit(X_train, y_train)\n",
    "        y_pred_boosting = boosting_clf.predict(X_test)\n",
    "\n",
    "        # 评估性能\n",
    "        top1_boosting.append(accuracy_score(y_test, y_pred_boosting))\n",
    "\n",
    "        end_time_boosting=time.time()\n",
    "        boosting_time=end_time_boosting-start_time_boosting\n",
    "        time_boosting.append(boosting_time)\n",
    "        \n",
    "        joblib.dump(boosting_clf,f'{target_dir}/boosting_cifar100_{i}.pkl')    \n",
    "    \n",
    "    return time_boosting,top1_boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10/10 [87:05:10<00:00, 31351.04s/it]\n"
     ]
    }
   ],
   "source": [
    "time_boosting1,top1_boosting1=boosting_clf(classifier1,'model_cifar100/model1_boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boosting_cifar100_100.pkl', 'boosting_cifar100_120.pkl', 'boosting_cifar100_140.pkl', 'boosting_cifar100_170.pkl', 'boosting_cifar100_20.pkl', 'boosting_cifar100_200.pkl', 'boosting_cifar100_300.pkl', 'boosting_cifar100_40.pkl', 'boosting_cifar100_60.pkl', 'boosting_cifar100_80.pkl']\n"
     ]
    }
   ],
   "source": [
    "pkl_size_boosting1=get_dir_size('model_cifar100/model1_boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   基分类器个数  performance            时间  pkl_size_boosting\n",
      "0      20     0.064667   7210.759424          93.361950\n",
      "1      40     0.067111  12062.219180         108.047668\n",
      "2      60     0.064556  19304.842715         124.650166\n",
      "3      80     0.064278  21464.824920         149.749834\n",
      "4     100     0.062778  25223.121325          40.142467\n",
      "5     120     0.065056  29111.428207         175.236450\n",
      "6     140     0.068111  31685.369305         266.962607\n",
      "7     170     0.073944  39697.124073          56.431488\n",
      "8     200     0.079944  53890.372960          68.336735\n",
      "9     300     0.091167  73854.381379          81.231392\n"
     ]
    }
   ],
   "source": [
    "#保存结果\n",
    "n= [20,40,60,80,100,120,140,170,200,300]\n",
    "import pandas as pd\n",
    "cb1={\"基分类器个数\" : n,\n",
    "   \"performance\" : top1_boosting1,\n",
    "  \"时间\":time_boosting1,\n",
    "  \"pkl_size_boosting\":pkl_size_boosting1}#将列表a，b转换成字典\n",
    "boost_result1=pd.DataFrame(cb1)#将字典转换成为数据框\n",
    "print(boost_result1)\n",
    "boost_result1.to_csv('model_cifar100/boosting_cifar100_result1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调整m个数重新运行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调整max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= [20,40,60,80,100,120,140,170,200,300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基分类器2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08594444444444445\n"
     ]
    }
   ],
   "source": [
    "start_time_base2=time.time()\n",
    "classifier2=DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=10,min_samples_split=5,random_state=42)#第一次测试最优\n",
    "classifier2.fit(X_train,y_train)\n",
    "score2=classifier2.score(X_test,y_test)\n",
    "print(score2)\n",
    "end_time_base2=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基分类器所用时间： 189.77275609970093\n"
     ]
    }
   ],
   "source": [
    "base_time2=end_time_base2-start_time_base2\n",
    "print('基分类器所用时间：',base_time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_cifar100/base2_learner_cifar100.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "#保存Model\n",
    "joblib.dump(classifier2,'model_cifar100/base2_learner_cifar100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2007503509521484\n"
     ]
    }
   ],
   "source": [
    "print(os.path.getsize('model_cifar100/base2_learner_cifar100.pkl')/1024/1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 10/10 [4:55:47<00:00, 1774.78s/it]\n"
     ]
    }
   ],
   "source": [
    "time_bagging2,top1_bagging2=bagging_clf(classifier2,'model_cifar100/model2_bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bagging_cifar100_100.pkl', 'bagging_cifar100_120.pkl', 'bagging_cifar100_140.pkl', 'bagging_cifar100_170.pkl', 'bagging_cifar100_20.pkl', 'bagging_cifar100_200.pkl', 'bagging_cifar100_300.pkl', 'bagging_cifar100_40.pkl', 'bagging_cifar100_60.pkl', 'bagging_cifar100_80.pkl']\n"
     ]
    }
   ],
   "source": [
    "pkl_size_bagging2=get_dir_size('model_cifar100/model2_bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   基分类器个数  performance           时间  pkl_size_bagging\n",
      "0      20     0.144778   300.192063         97.556987\n",
      "1      40     0.154611   613.908269        116.610899\n",
      "2      60     0.160444   872.239505        135.898277\n",
      "3      80     0.162444  1092.600025        164.715873\n",
      "4     100     0.164722  1382.051738         20.041725\n",
      "5     120     0.166556  1559.851910        193.399596\n",
      "6     140     0.167611  1866.024740        289.172002\n",
      "7     170     0.168611  2238.049685         39.293176\n",
      "8     200     0.168889  2541.762230         58.706294\n",
      "9     300     0.170389  5272.253625         78.165116\n"
     ]
    }
   ],
   "source": [
    "#保存结果\n",
    "import pandas as pd\n",
    "n= [20,40,60,80,100,120,140,170,200,300]\n",
    "c2={\"基分类器个数\" : n,\n",
    "   \"performance\" : top1_bagging2,\n",
    "  \"时间\":time_bagging2,\n",
    "  \"pkl_size_bagging\":pkl_size_bagging2}#将列表a，b转换成字典\n",
    "bagging_result2=pd.DataFrame(c2)#将字典转换成为数据框\n",
    "print(bagging_result2)\n",
    "bagging_result2.to_csv('model_cifar100/bagging_cifar100_result2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10/10 [85:01:26<00:00, 30608.62s/it]\n"
     ]
    }
   ],
   "source": [
    "time_boosting2,top1_boosting2=boosting_clf(classifier2,'model_cifar100/model2_boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boosting_cifar100_100.pkl', 'boosting_cifar100_120.pkl', 'boosting_cifar100_140.pkl', 'boosting_cifar100_170.pkl', 'boosting_cifar100_20.pkl', 'boosting_cifar100_200.pkl', 'boosting_cifar100_300.pkl', 'boosting_cifar100_40.pkl', 'boosting_cifar100_60.pkl', 'boosting_cifar100_80.pkl']\n"
     ]
    }
   ],
   "source": [
    "pkl_size_boosting2=get_dir_size('model_cifar100/model2_boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   基分类器个数  performance            时间  pkl_size_boosting\n",
      "0      20     0.068222   3434.388138          24.476971\n",
      "1      40     0.060000   7307.279373          27.573801\n",
      "2      60     0.062667  13853.059575          30.373479\n",
      "3      80     0.063889  19792.524408          34.027673\n",
      "4     100     0.064500  25413.495997           7.808658\n",
      "5     120     0.062000  30840.283103          37.921875\n",
      "6     140     0.058111  32464.849141          50.868814\n",
      "7     170     0.056056  46044.769627          12.541475\n",
      "8     200     0.054889  45727.210762          16.810600\n",
      "9     300     0.054556  81204.494751          20.818486\n"
     ]
    }
   ],
   "source": [
    "#保存结果\n",
    "import pandas as pd\n",
    "cb2={\"基分类器个数\" : n,\n",
    "   \"performance\" : top1_boosting2,\n",
    "  \"时间\":time_boosting2,\n",
    "  \"pkl_size_boosting\":pkl_size_boosting2}#将列表a，b转换成字典\n",
    "boost_result2=pd.DataFrame(cb2)#将字典转换成为数据框\n",
    "print(boost_result2)\n",
    "boost_result2.to_csv('model_cifar100/boosting_cifar100_result2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基分类器3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08172222222222222\n"
     ]
    }
   ],
   "source": [
    "start_time_base3=time.time()\n",
    "classifier3=DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=8,min_samples_split=5,random_state=42)#第一次测试最优\n",
    "classifier3.fit(X_train,y_train)\n",
    "score3=classifier3.score(X_test,y_test)\n",
    "print(score3)\n",
    "end_time_base3=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基分类器所用时间： 190.1080286502838\n"
     ]
    }
   ],
   "source": [
    "base_time3=end_time_base3-start_time_base3\n",
    "print('基分类器所用时间：',base_time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_cifar100/base3_learner_cifar100.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "#保存Model\n",
    "joblib.dump(classifier3,'model_cifar100/base3_learner_cifar100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39746665954589844\n"
     ]
    }
   ],
   "source": [
    "print(os.path.getsize('model_cifar100/base3_learner_cifar100.pkl')/1024/1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 10/10 [3:39:02<00:00, 1314.30s/it]\n"
     ]
    }
   ],
   "source": [
    "time_bagging3,top1_bagging3=bagging_clf(classifier3,'model_cifar100/model3_bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bagging_cifar100_100.pkl', 'bagging_cifar100_120.pkl', 'bagging_cifar100_140.pkl', 'bagging_cifar100_170.pkl', 'bagging_cifar100_20.pkl', 'bagging_cifar100_200.pkl', 'bagging_cifar100_300.pkl', 'bagging_cifar100_40.pkl', 'bagging_cifar100_60.pkl', 'bagging_cifar100_80.pkl']\n"
     ]
    }
   ],
   "source": [
    "pkl_size_bagging3=get_dir_size('model_cifar100/model3_bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   基分类器个数  performance           时间  pkl_size_bagging\n",
      "0      20     0.131556   274.702234         38.491145\n",
      "1      40     0.137500   483.918506         46.073774\n",
      "2      60     0.140889   669.602207         53.689049\n",
      "3      80     0.143111   966.434433         65.123389\n",
      "4     100     0.145556  1065.712024          7.897774\n",
      "5     120     0.147056  1274.405816         76.409163\n",
      "6     140     0.147556  1485.410996        114.256978\n",
      "7     170     0.147667  1741.001485         15.552224\n",
      "8     200     0.148389  2015.369994         23.206706\n",
      "9     300     0.150278  3160.239135         30.831788\n"
     ]
    }
   ],
   "source": [
    "#保存结果\n",
    "import pandas as pd\n",
    "c3={\"基分类器个数\" : n,\n",
    "   \"performance\" : top1_bagging3,\n",
    "  \"时间\":time_bagging3,\n",
    "  \"pkl_size_bagging\":pkl_size_bagging3}#将列表a，b转换成字典\n",
    "bagging_result3=pd.DataFrame(c3)#将字典转换成为数据框\n",
    "print(bagging_result3)\n",
    "bagging_result3.to_csv('model_cifar100/bagging_cifar100_result3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10/10 [45:39:30<00:00, 16437.02s/it]\n"
     ]
    }
   ],
   "source": [
    "time_boosting3,top1_boosting3=boosting_clf(classifier3,'model_cifar100/model3_boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boosting_cifar100_100.pkl', 'boosting_cifar100_120.pkl', 'boosting_cifar100_140.pkl', 'boosting_cifar100_170.pkl', 'boosting_cifar100_20.pkl', 'boosting_cifar100_200.pkl', 'boosting_cifar100_300.pkl', 'boosting_cifar100_40.pkl', 'boosting_cifar100_60.pkl', 'boosting_cifar100_80.pkl']\n"
     ]
    }
   ],
   "source": [
    "pkl_size_boosting3=get_dir_size('model_cifar100/model3_boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   基分类器个数  performance            时间  pkl_size_boosting\n",
      "0      20     0.068278   3319.988853          14.403131\n",
      "1      40     0.064167   6386.744726          16.337480\n",
      "2      60     0.063333   9344.196559          18.229379\n",
      "3      80     0.061944  11856.188519          21.080289\n",
      "4     100     0.062556  12887.429691           3.893426\n",
      "5     120     0.061444  15784.988125          23.640580\n",
      "6     140     0.059833  18418.236914          31.305752\n",
      "7     170     0.057667  22376.350152           6.970658\n",
      "8     200     0.056778  25695.599679           9.739312\n",
      "9     300     0.055278  38298.425575          12.202653\n"
     ]
    }
   ],
   "source": [
    "#保存结果\n",
    "import pandas as pd\n",
    "cb3={\"基分类器个数\" : n,\n",
    "   \"performance\" : top1_boosting3,\n",
    "  \"时间\":time_boosting3,\n",
    "  \"pkl_size_boosting\":pkl_size_boosting3}#将列表a，b转换成字典\n",
    "boost_result3=pd.DataFrame(cb3)#将字典转换成为数据框\n",
    "print(boost_result3)\n",
    "boost_result3.to_csv('model_cifar100/boosting_cifar100_result3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
